{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Petroglyphs Segmentation Model - Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a Custom Dice Loss class\n",
    "\n",
    "\n",
    "\n",
    "$\\text{Given a predicted mask }  p \\text{ and the ground truth target } t, \\text{ with a smoothing factor } s, \\text{ the Dice Loss } L \\text{ is defined as:}$\n",
    "\n",
    "#### $L = 1 - \\frac{2 \\cdot \\sum(p \\cdot t) + s}{\\sum(p^{2}) + \\sum(t^{2}) + s}$\n",
    "\n",
    "The smoothing factor is a very small number added to avoid division by 0. Read more about Dice Loss [here](https://arxiv.org/pdf/1606.04797.pdf) (on page 6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from PIL import Image\n",
    "import os\n",
    "from torch import nn\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data into Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define transforms for images and masks\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Custom Dataset class to preload images and masks into memory\n",
    "class PreloadedDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.image_files = sorted(os.listdir(os.path.join(root_dir, 'Unlabelled_Images')))\n",
    "        self.mask_files = sorted(os.listdir(os.path.join(root_dir, 'Labels')))\n",
    "        self.images = []\n",
    "        self.masks = []\n",
    "        self.transform = transform\n",
    "        self._preload_data()\n",
    "\n",
    "    def _preload_data(self):\n",
    "        for image_file, mask_file in zip(self.image_files, self.mask_files):\n",
    "            image_path = os.path.join(self.root_dir, 'Unlabelled_Images', image_file)\n",
    "            mask_path = os.path.join(self.root_dir, 'Labels', mask_file)\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            mask = Image.open(mask_path).convert(\"L\")\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "                mask = self.transform(mask)\n",
    "            self.images.append(image)\n",
    "            self.masks.append(mask)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.masks[idx]\n",
    "\n",
    "dataset = PreloadedDataset(root_dir='', transform=transform)\n",
    "\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "b = 4\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=b, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=b)\n",
    "\n",
    "# Load pre-trained DeepLabv3+ model\n",
    "model = models.segmentation.deeplabv3_resnet50(weights=models.segmentation.DeepLabV3_ResNet50_Weights.DEFAULT)\n",
    "\n",
    "# Modify last layer for binary segmentation\n",
    "num_classes = 1\n",
    "model.classifier[4] = nn.Sequential(\n",
    "    nn.Conv2d(256, num_classes, kernel_size=(1, 1), stride=(1, 1)),\n",
    "    nn.Sigmoid())\n",
    "\n",
    "# Load model on CPU\n",
    "model.load_state_dict(torch.load(\"deeplabv3_small_ubaid.pth\", map_location=torch.device('cpu')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0+cpu'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[0;32m     39\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m---> 41\u001b[0m \u001b[43mvisualize_predictions_grid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 8\u001b[0m, in \u001b[0;36mvisualize_predictions_grid\u001b[1;34m(model, dataloader, num_samples)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisualize_predictions_grid\u001b[39m(model, dataloader, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# model.cuda()\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m----> 8\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     total_rows \u001b[38;5;241m=\u001b[39m num_samples\n\u001b[0;32m     11\u001b[0m     cols_per_sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n",
      "File \u001b[1;32mmtrand.pyx:1000\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Function to visualize images and masks in a grid\n",
    "def visualize_predictions_grid(model, dataloader, num_samples=10):\n",
    "    # model.cuda()\n",
    "    model.eval()\n",
    "    samples = np.random.choice(len(dataloader.dataset), num_samples, replace=False)\n",
    "\n",
    "    total_rows = num_samples\n",
    "    cols_per_sample = 3\n",
    "    plt.figure(figsize=(cols_per_sample * 5, total_rows * 5))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, idx in enumerate(samples):\n",
    "            image, mask = dataloader.dataset[idx]\n",
    "            image = image.unsqueeze(0).cuda()\n",
    "            mask = mask.unsqueeze(0)\n",
    "            output = model(image)['out'] >= 0.5 # defined the threshold at 0.4, can experiment with different values\n",
    "            pred_mask = output.squeeze().cpu().numpy()\n",
    "\n",
    "            plt.subplot(total_rows, cols_per_sample, i * cols_per_sample + 1)\n",
    "            plt.imshow(transforms.ToPILImage()(image.squeeze()))\n",
    "            plt.title(f'Image {i+1}')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(total_rows, cols_per_sample, i * cols_per_sample + 2)\n",
    "            plt.imshow(transforms.ToPILImage()(mask.squeeze()), cmap='gray')\n",
    "            plt.title(f'Ground Truth {i+1}')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(total_rows, cols_per_sample, i * cols_per_sample + 3)\n",
    "            plt.imshow(pred_mask, cmap='gray')\n",
    "            plt.title(f'Predicted {i+1}')\n",
    "            plt.axis('off')\n",
    "\n",
    "    # Display the full grid\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_predictions_grid(model, val_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice coefficient is: 0.777\n",
      "IoU: 0.629\n"
     ]
    }
   ],
   "source": [
    "def dice_coef(groundtruth_mask, pred_mask):\n",
    "    intersect = np.sum(pred_mask*groundtruth_mask)\n",
    "    total_sum = np.sum(pred_mask**2) + np.sum(groundtruth_mask**2)\n",
    "    dice = np.mean(2*intersect/total_sum)\n",
    "    return round(dice, 3) #round up to 3 decimal places\n",
    "\n",
    "def iou(groundtruth_mask, pred_mask):\n",
    "    intersect = np.sum(pred_mask*groundtruth_mask)\n",
    "    union = np.sum(pred_mask) + np.sum(groundtruth_mask) - intersect\n",
    "    iou = np.mean(intersect/union)\n",
    "    return round(iou, 3)\n",
    "\n",
    "true = []\n",
    "pred = []\n",
    "for imgs, mask in val_dataloader:\n",
    "    true.extend([m.cpu().numpy().reshape(1, 512, 512) for m in mask])\n",
    "    with torch.no_grad():\n",
    "        imgs = imgs.reshape(-1, 3, 512, 512).cuda()\n",
    "        outputs = model(imgs)['out'].detach().cpu().numpy() >= 0.5\n",
    "    pred.extend([m for m in outputs])\n",
    "\n",
    "true = np.array(true)\n",
    "pred = np.array(pred)\n",
    "print(\"Dice coefficient is:\",dice_coef(true,pred))\n",
    "print(\"IoU:\", iou(true,pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
